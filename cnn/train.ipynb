{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create shifted versions.  \n",
    "This is not redundant, even though we are using convolutional layers, as there are boundary effects (especially with the very small size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 5\n",
    "HEIGHT = 5\n",
    "\n",
    "with open(\"data.txt\") as f:\n",
    "    t = f.read()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for ex in t.split(\"\\n\\n\"):\n",
    "    lines = ex.split(\"\\n\")\n",
    "    y  = int(lines[0])\n",
    "    x = np.array([[0 if x == \".\" else 1 for x in line] for line in lines[1:]])\n",
    "    \n",
    "    ex_width = np.max(np.arange(1, WIDTH + 1) * x)\n",
    "    ex_height = np.max((np.arange(1, HEIGHT + 1) * x.T).T)\n",
    "    print(y, ex_width, ex_height, end=\"\")\n",
    "    for offset_x, offset_y in itertools.product(range(WIDTH - ex_width + 1),\n",
    "                                                range(HEIGHT - ex_height + 1)):\n",
    "        xs.append(np.roll(x, (offset_y, offset_x), axis=(0, 1)))\n",
    "        ys.append(y)\n",
    "        print(\".\", end=\"\")\n",
    "    print()\n",
    "\n",
    "xs = np.array(xs).astype(float)[..., np.newaxis]\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# of (shifted) examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, len(ys))\n",
    "print(ys[i])\n",
    "print(xs[i,:,:,0].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add augmentation & create tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(x: np.ndarray, xs_strings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Randomly flips a bit in x, ensuring that the resulting pattern\n",
    "       does not occurr in xs_strings\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        x_new = x.copy()\n",
    "        pos_y = np.random.randint(0, HEIGHT)\n",
    "        pos_x = np.random.randint(0, WIDTH)\n",
    "        x_new[pos_y, pos_x] = 1 - x_new[pos_y, pos_x]\n",
    "        if x_new.tostring() not in xs_strings:\n",
    "            return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_strings = {x.tostring() for x in xs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_onehot = tf.keras.utils.to_categorical(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "ds = tf.data.Dataset.zip((\n",
    "    tf.data.Dataset.from_tensor_slices(xs),\n",
    "    tf.data.Dataset.from_tensor_slices(ys_onehot)\n",
    ")).shuffle(buffer_size=len(ys)).repeat()\n",
    "\n",
    "def augment(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flip up to 3 bits randomly\"\"\"\n",
    "    if np.random.uniform() > 0.6:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.85:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.95:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def map_fn(x: tf.Tensor, y: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = tf.numpy_function(func=augment , inp=[x], Tout=tf.float64)\n",
    "    x.set_shape([HEIGHT, WIDTH, 1])\n",
    "    return x, y\n",
    "\n",
    "ds = ds.map(map_fn, num_parallel_calls=8)\n",
    "ds = ds.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "regularization actually improves accuracy on the non-augmented (flipped) samples and makes led activation patterns nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = 0.004\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 2,\n",
    "        activation=\"relu\", padding=\"valid\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),\n",
    "        input_shape=(WIDTH, HEIGHT, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 2, activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),),\n",
    "    tf.keras.layers.Conv2D(16, 2, activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=l2_reg),),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025),\n",
    "    metrics=[\"accuracy\"],\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training is fast, so let's just go crazy with the number of epochs\n",
    "for i in range(100):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys_onehot, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.0005)\n",
    "for i in range(40):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys_onehot, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "for i in range(40):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys_onehot, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds, steps=len(ys) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(xs, ys_onehot, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xs)\n",
    "pred_classes = np.argmax(preds, axis=1)\n",
    "wrong = pred_classes != ys\n",
    "display(xs[wrong][...,0])\n",
    "display(preds[wrong])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"5x5_4-8-16_filters.savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"5x5_4-8-16_filters.savedmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [0,1,1,1,0],\n",
    "    [0,1,1,1,0],\n",
    "    [0,0,0,1,0],\n",
    "    [0,1,1,1,0]\n",
    "    ])[np.newaxis,..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    base_name = f\"weights/conv{i}_{{}}.npy\"\n",
    "    kernel, bias = model.layers[i].weights\n",
    "    np.save(base_name.format(\"kernel\"), kernel.numpy())\n",
    "    np.save(base_name.format(\"bias\"), bias.numpy())\n",
    "    \n",
    "kernel, bias = model.layers[4].weights\n",
    "np.save(\"weights/dense_kernel.npy\", kernel.numpy())\n",
    "np.save(\"weights/dense_bias.npy\", bias.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output model for inclusion in C code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 99th percentile activation strengths for led brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xs\n",
    "for i in range(3):\n",
    "    x = model.layers[i](x)\n",
    "    perc_99 = np.percentile(x, 99)\n",
    "    print(f\"const float conv{i}_activation_99per = {np.format_float_positional(perc_99)};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_float_array(name: str, x: np.ndarray) -> None:\n",
    "    assert(len(x.shape) == 1)\n",
    "    print(f\"const float {name}[] = {{\")\n",
    "    for i in range(int(np.ceil(len(x) / 5))):\n",
    "        print(\"    \" + \", \".join(np.format_float_scientific(f) for f in x[i*5: i*5 + 5]) + \",\")\n",
    "    print(\"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print_float_array(\n",
    "        f\"conv{i}_kernel_data\",\n",
    "        model.layers[i].weights[0].numpy().flatten()\n",
    "    )\n",
    "    print()\n",
    "    print_float_array(\n",
    "        f\"conv{i}_bias_data\",\n",
    "        model.layers[i].weights[1].numpy().flatten()\n",
    "    )\n",
    "    print()\n",
    "    \n",
    "print_float_array(\n",
    "    \"dense_kernel_data\",\n",
    "    model.layers[4].weights[0].numpy().T.flatten()\n",
    ")\n",
    "print()\n",
    "print_float_array(\n",
    "    \"dense_bias_data\",\n",
    "    model.layers[4].weights[1].numpy().flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
