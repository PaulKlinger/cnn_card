{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create shifted versions.  \n",
    "This is not redundant, even though we are using convolutional layers, as there are boundary effects (especially with the very small size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 3.........\n",
      "0 3 3.........\n",
      "0 4 4....\n",
      "0 3 4......\n",
      "0 3 4......\n",
      "0 3 4......\n",
      "0 3 5...\n",
      "0 4 4....\n",
      "0 4 5..\n",
      "0 4 4....\n",
      "0 4 5..\n",
      "0 5 5.\n",
      "1 1 5.....\n",
      "1 1 4..........\n",
      "1 1 3...............\n",
      "1 3 3.........\n",
      "1 2 4........\n",
      "1 3 4......\n",
      "1 3 4......\n",
      "1 3 5...\n",
      "1 3 4......\n",
      "1 3 4......\n",
      "2 5 5.\n",
      "2 3 5...\n",
      "2 3 3.........\n",
      "2 3 5...\n",
      "2 5 5.\n",
      "2 4 5..\n",
      "2 5 5.\n",
      "2 5 5.\n",
      "2 5 5.\n",
      "2 3 4......\n",
      "2 3 4......\n",
      "2 3 5...\n",
      "2 3 4......\n",
      "3 3 3.........\n",
      "3 2 3............\n",
      "3 4 5..\n",
      "3 4 5..\n",
      "3 3 5...\n",
      "3 2 5....\n",
      "3 4 5..\n",
      "3 5 5.\n",
      "3 3 5...\n",
      "3 5 5.\n",
      "3 5 5.\n",
      "3 4 5..\n",
      "3 3 5...\n",
      "3 3 5...\n",
      "3 4 5..\n",
      "3 4 5..\n",
      "3 3 3.........\n",
      "3 3 4......\n",
      "3 3 4......\n",
      "3 3 4......\n",
      "4 4 5..\n",
      "4 4 5..\n",
      "4 5 5.\n",
      "4 4 5..\n",
      "4 4 5..\n",
      "4 3 3.........\n",
      "4 2 4........\n",
      "4 2 3............\n",
      "4 4 4....\n",
      "4 4 4....\n",
      "4 5 5.\n",
      "4 4 5..\n",
      "4 3 4......\n",
      "4 3 4......\n",
      "5 4 5..\n",
      "5 4 5..\n",
      "5 3 5...\n",
      "5 3 5...\n",
      "5 3 5...\n",
      "5 4 5..\n",
      "5 5 5.\n",
      "5 2 4........\n",
      "5 3 4......\n",
      "5 3 3.........\n",
      "5 3 4......\n",
      "5 3 4......\n",
      "5 3 4......\n",
      "5 4 4....\n",
      "5 2 5....\n",
      "5 2 5....\n",
      "5 2 5....\n",
      "6 3 5...\n",
      "6 3 4......\n",
      "6 3 5...\n",
      "6 3 3.........\n",
      "6 2 3............\n",
      "6 2 4........\n",
      "6 3 5...\n",
      "6 2 4........\n",
      "6 3 4......\n",
      "6 3 4......\n",
      "6 3 4......\n",
      "6 4 4....\n",
      "7 3 4......\n",
      "7 4 5..\n",
      "7 5 5.\n",
      "7 5 5.\n",
      "7 3 4......\n",
      "7 3 3.........\n",
      "7 4 4....\n",
      "7 5 5.\n",
      "7 5 5.\n",
      "8 3 4......\n",
      "8 3 4......\n",
      "8 3 4......\n",
      "8 3 3.........\n",
      "8 4 4....\n",
      "8 4 4....\n",
      "8 5 5.\n",
      "8 5 5.\n",
      "8 5 5.\n",
      "8 3 5...\n",
      "8 4 5..\n",
      "8 5 5.\n",
      "9 5 5.\n",
      "9 5 5.\n",
      "9 3 5...\n",
      "9 3 5...\n",
      "9 3 4......\n",
      "9 3 5...\n",
      "9 3 4......\n",
      "9 3 3.........\n",
      "9 2 3............\n",
      "9 4 4....\n",
      "9 3 4......\n",
      "9 3 4......\n",
      "9 3 4......\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 5\n",
    "HEIGHT = 5\n",
    "\n",
    "with open(\"data.txt\") as f:\n",
    "    t = f.read()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for ex in t.split(\"\\n\\n\"):\n",
    "    lines = ex.split(\"\\n\")\n",
    "    y  = int(lines[0])\n",
    "    x = np.array([[0 if x == \".\" else 1 for x in line] for line in lines[1:]])\n",
    "    \n",
    "    ex_width = np.max(np.arange(1, WIDTH + 1) * x)\n",
    "    ex_height = np.max((np.arange(1, HEIGHT + 1) * x.T).T)\n",
    "    print(y, ex_width, ex_height, end=\"\")\n",
    "    for offset_x, offset_y in itertools.product(range(WIDTH - ex_width + 1),\n",
    "                                                range(HEIGHT - ex_height + 1)):\n",
    "        xs.append(np.roll(x, (offset_y, offset_x), axis=(0, 1)))\n",
    "        ys.append(y)\n",
    "        print(\".\", end=\"\")\n",
    "    print()\n",
    "\n",
    "xs = np.array(xs).astype(float)[..., np.newaxis]\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# of (shifted) examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    79\n",
       "6    74\n",
       "1    74\n",
       "5    73\n",
       "9    66\n",
       "4    61\n",
       "0    56\n",
       "8    44\n",
       "2    43\n",
       "7    31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[0 0 1 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(ys))\n",
    "print(ys[i])\n",
    "print(xs[i,:,:,0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(x: np.ndarray, xs_strings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Randomly flips a bit in x, ensuring that the resulting pattern\n",
    "       does not occurr in xs_strings\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        x_new = x.copy()\n",
    "        pos_y = np.random.randint(0, HEIGHT)\n",
    "        pos_x = np.random.randint(0, WIDTH)\n",
    "        x_new[pos_y, pos_x] = 1 - x_new[pos_y, pos_x]\n",
    "        if x_new.tostring() not in xs_strings:\n",
    "            return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_strings = {x.tostring() for x in xs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "ds = tf.data.Dataset.zip((\n",
    "    tf.data.Dataset.from_tensor_slices(xs),\n",
    "    tf.data.Dataset.from_tensor_slices(ys)\n",
    ")).shuffle(buffer_size=len(ys)).repeat()\n",
    "\n",
    "def augment(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flip up to 3 bits randomly\"\"\"\n",
    "    if np.random.uniform() > 0.6:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.85:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.95:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def map_fn(x: tf.Tensor, y: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = tf.numpy_function(func=augment , inp=[x], Tout=tf.float64)\n",
    "    x.set_shape([HEIGHT, WIDTH, 1])\n",
    "    return x, y\n",
    "\n",
    "ds = ds.map(map_fn, num_parallel_calls=8)\n",
    "ds = ds.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(4, 2, activation=\"relu\", padding=\"valid\", input_shape=(WIDTH, HEIGHT, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 2,  activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(16, 2,  activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025), metrics=[\"accuracy\"], loss=tf.keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5875214978978163, 0.4342762]\n",
      "[0.8785768717576977, 0.70216304]\n",
      "[0.5461915427952162, 0.84858567]\n",
      "[0.41655132040604576, 0.8935108]\n",
      "[0.34321776409315785, 0.9267887]\n",
      "[0.3063359028487753, 0.9267887]\n",
      "[0.27414292345031127, 0.9384359]\n",
      "[0.24537700717143726, 0.953411]\n",
      "[0.2250930157655884, 0.96339434]\n",
      "[0.2110891010915975, 0.96672213]\n",
      "[0.19848495786281276, 0.96339434]\n",
      "[0.18753172008447758, 0.96672213]\n",
      "[0.17774632945036928, 0.9733777]\n",
      "[0.17692251595205158, 0.97504157]\n",
      "[0.16352415493938965, 0.9800333]\n",
      "[0.1592432604157389, 0.97836936]\n",
      "[0.14995828094875158, 0.97504157]\n",
      "[0.14775649323042936, 0.98169714]\n",
      "[0.14361647222680776, 0.9800333]\n",
      "[0.13877129490284276, 0.98336107]\n",
      "[0.13671101800812263, 0.98668885]\n",
      "[0.1368089908619292, 0.98668885]\n",
      "[0.1299950772285858, 0.98336107]\n",
      "[0.12354691150581182, 0.99001664]\n",
      "[0.1317159654495125, 0.98668885]\n",
      "[0.11858940300548731, 0.9916805]\n",
      "[0.11993231206586873, 0.99001664]\n",
      "[0.11718819048658584, 0.9916805]\n",
      "[0.1229554431361089, 0.99001664]\n",
      "[0.10639031774390756, 0.9933444]\n",
      "[0.11613097722439124, 0.98668885]\n",
      "[0.10929106249041645, 0.9916805]\n",
      "[0.11008412275655496, 0.9950083]\n",
      "[0.1066973812865735, 0.99001664]\n",
      "[0.11204461696342304, 0.9916805]\n",
      "[0.0998174217893756, 0.9933444]\n",
      "[0.10137597001630336, 0.9966722]\n",
      "[0.10222649687092236, 0.9933444]\n",
      "[0.10288561332642338, 0.9950083]\n",
      "[0.09674748557677086, 0.9950083]\n",
      "[0.098760315265116, 0.9916805]\n",
      "[0.09907682059013506, 0.9933444]\n",
      "[0.09764904899525761, 0.9916805]\n",
      "[0.09420258219597145, 0.9933444]\n",
      "[0.09020976273470036, 0.9966722]\n",
      "[0.09768212181260304, 0.9966722]\n",
      "[0.09096741728397852, 0.9983361]\n",
      "[0.09186913430095711, 0.9966722]\n",
      "[0.09105294412265404, 0.9966722]\n",
      "[0.08764124981525932, 0.9950083]\n"
     ]
    }
   ],
   "source": [
    "# training is fast, so let's just go crazy with the number of epochs\n",
    "for i in range(50):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0005>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08378180686675768, 0.9983361]\n",
      "[0.08266442559175999, 0.9966722]\n",
      "[0.08259089386552423, 0.9966722]\n",
      "[0.08277329469034557, 0.9966722]\n",
      "[0.08343032980570182, 0.9966722]\n",
      "[0.08216995145883814, 0.9966722]\n",
      "[0.08163688189277236, 0.9966722]\n",
      "[0.08198392936671633, 0.9966722]\n",
      "[0.08212041901966895, 0.9966722]\n",
      "[0.08243998907469274, 0.9983361]\n",
      "[0.08120984948564092, 0.9983361]\n",
      "[0.0825885234527699, 0.9966722]\n",
      "[0.08261346446347118, 0.9983361]\n",
      "[0.081855698180278, 0.9983361]\n",
      "[0.0811349679398259, 0.9983361]\n",
      "[0.08232082062077006, 0.9983361]\n",
      "[0.08068347562370999, 0.9983361]\n",
      "[0.08148023616305604, 0.9966722]\n",
      "[0.08137531521514728, 0.9983361]\n",
      "[0.08173648129138296, 0.9983361]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08067461735446521, 0.9983361]\n",
      "[0.08020514459310474, 0.9983361]\n",
      "[0.08047649403181727, 0.9983361]\n",
      "[0.08000410159742971, 0.9983361]\n",
      "[0.08002653043599375, 0.9983361]\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "for i in range(5):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4607 - accuracy: 0.8691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46074575185775757, 0.8691406]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds, steps=len(ys) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08002653043599375, 0.9983361]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[model.predict_classes(xs) != ys][...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kling\\cv_homework\\cv_venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 5x5_4-8-16_filters.savedmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"5x5_4-8-16_filters.savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"5x5_4-8-16_filters.savedmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 4)           20        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 8)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 16)          528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 854\n",
      "Trainable params: 854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    base_name = f\"weights/conv{i}_{{}}.npy\"\n",
    "    kernel, bias = model.layers[i].weights\n",
    "    np.save(base_name.format(\"kernel\"), kernel.numpy())\n",
    "    np.save(base_name.format(\"bias\"), bias.numpy())\n",
    "    \n",
    "kernel, bias = model.layers[4].weights\n",
    "np.save(\"weights/dense_kernel.npy\", kernel.numpy())\n",
    "np.save(\"weights/dense_bias.npy\", bias.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [1,1,1,0,0],\n",
    "    [1,1,1,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,0,0]\n",
    "    ])[np.newaxis,..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1215, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[4.7821915e-05, 1.0191064e-03, 5.8183535e-03, 9.3612295e-01,\n",
       "        2.4241449e-06, 7.1806074e-03, 3.5705147e-04, 9.8084245e-05,\n",
       "        3.8822528e-02, 1.0531087e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.466181516647339"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(model.layers[0](xs).numpy(), 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0](xs).numpy().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8704609870910645"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(model.layers[1](model.layers[0](xs)).numpy(), 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.721277723312408"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(\n",
    "    model.layers[2](model.layers[1](model.layers[0](xs))).numpy(), 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.385940551757812"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(\n",
    "    model.layers[3](\n",
    "        model.layers[2](\n",
    "            model.layers[1](\n",
    "                model.layers[0](xs)\n",
    "            ))).numpy(), 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
