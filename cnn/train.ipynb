{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create shifted versions.  \n",
    "This is not redundant, even though we are using convolutional layers, as there are boundary effects (especially with the very small size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 3.........\n",
      "0 3 3.........\n",
      "0 4 4....\n",
      "0 3 4......\n",
      "0 3 4......\n",
      "0 3 4......\n",
      "0 3 5...\n",
      "0 4 4....\n",
      "0 4 5..\n",
      "0 4 4....\n",
      "0 4 5..\n",
      "0 5 5.\n",
      "1 1 5.....\n",
      "1 1 4..........\n",
      "1 1 3...............\n",
      "1 3 3.........\n",
      "1 2 4........\n",
      "1 3 4......\n",
      "1 3 4......\n",
      "1 3 5...\n",
      "1 3 4......\n",
      "1 3 4......\n",
      "2 5 5.\n",
      "2 3 3.........\n",
      "2 3 5...\n",
      "2 5 5.\n",
      "2 4 5..\n",
      "2 5 5.\n",
      "2 5 5.\n",
      "2 5 5.\n",
      "2 3 4......\n",
      "2 3 4......\n",
      "2 3 5...\n",
      "2 3 4......\n",
      "3 3 3.........\n",
      "3 2 3............\n",
      "3 4 5..\n",
      "3 4 5..\n",
      "3 3 5...\n",
      "3 2 5....\n",
      "3 4 5..\n",
      "3 5 5.\n",
      "3 3 5...\n",
      "3 5 5.\n",
      "3 5 5.\n",
      "3 4 5..\n",
      "3 3 5...\n",
      "3 3 5...\n",
      "3 4 5..\n",
      "3 4 5..\n",
      "3 3 3.........\n",
      "3 3 4......\n",
      "3 3 4......\n",
      "3 3 4......\n",
      "4 4 5..\n",
      "4 4 5..\n",
      "4 5 5.\n",
      "4 4 5..\n",
      "4 4 5..\n",
      "4 3 3.........\n",
      "4 4 4....\n",
      "4 4 4....\n",
      "4 5 5.\n",
      "4 4 5..\n",
      "4 3 4......\n",
      "4 3 4......\n",
      "5 4 5..\n",
      "5 4 5..\n",
      "5 3 5...\n",
      "5 3 5...\n",
      "5 3 5...\n",
      "5 4 5..\n",
      "5 5 5.\n",
      "5 2 4........\n",
      "5 3 4......\n",
      "5 3 3.........\n",
      "5 3 4......\n",
      "5 3 4......\n",
      "5 3 4......\n",
      "5 4 4....\n",
      "6 3 5...\n",
      "6 3 4......\n",
      "6 3 5...\n",
      "6 3 3.........\n",
      "6 3 5...\n",
      "6 2 4........\n",
      "6 3 4......\n",
      "6 3 4......\n",
      "6 3 4......\n",
      "6 4 4....\n",
      "7 3 4......\n",
      "7 4 5..\n",
      "7 5 5.\n",
      "7 5 5.\n",
      "7 3 4......\n",
      "7 3 3.........\n",
      "7 4 4....\n",
      "7 5 5.\n",
      "7 5 5.\n",
      "8 3 4......\n",
      "8 3 4......\n",
      "8 3 4......\n",
      "8 3 3.........\n",
      "8 4 4....\n",
      "8 4 4....\n",
      "8 5 5.\n",
      "8 5 5.\n",
      "8 5 5.\n",
      "8 3 5...\n",
      "8 4 5..\n",
      "8 5 5.\n",
      "9 5 5.\n",
      "9 5 5.\n",
      "9 3 5...\n",
      "9 3 5...\n",
      "9 3 4......\n",
      "9 3 5...\n",
      "9 3 4......\n",
      "9 3 3.........\n",
      "9 4 4....\n",
      "9 3 4......\n",
      "9 3 4......\n",
      "9 3 4......\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 5\n",
    "HEIGHT = 5\n",
    "\n",
    "with open(\"data.txt\") as f:\n",
    "    t = f.read()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for ex in t.split(\"\\n\\n\"):\n",
    "    lines = ex.split(\"\\n\")\n",
    "    y  = int(lines[0])\n",
    "    x = np.array([[0 if x == \".\" else 1 for x in line] for line in lines[1:]])\n",
    "    \n",
    "    ex_width = np.max(np.arange(1, WIDTH + 1) * x)\n",
    "    ex_height = np.max((np.arange(1, HEIGHT + 1) * x.T).T)\n",
    "    print(y, ex_width, ex_height, end=\"\")\n",
    "    for offset_x, offset_y in itertools.product(range(WIDTH - ex_width + 1),\n",
    "                                                range(HEIGHT - ex_height + 1)):\n",
    "        xs.append(np.roll(x, (offset_y, offset_x), axis=(0, 1)))\n",
    "        ys.append(y)\n",
    "        print(\".\", end=\"\")\n",
    "    print()\n",
    "\n",
    "xs = np.array(xs).astype(float)[..., np.newaxis]\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# of (shifted) examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    79\n",
       "1    74\n",
       "5    61\n",
       "0    56\n",
       "9    54\n",
       "6    54\n",
       "8    44\n",
       "4    41\n",
       "2    40\n",
       "7    31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[0 0 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(ys))\n",
    "print(ys[i])\n",
    "print(xs[i,:,:,0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(x: np.ndarray, xs_strings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Randomly flips a bit in x, ensuring that the resulting pattern\n",
    "       does not occurr in xs_strings\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        x_new = x.copy()\n",
    "        pos_y = np.random.randint(0, HEIGHT)\n",
    "        pos_x = np.random.randint(0, WIDTH)\n",
    "        x_new[pos_y, pos_x] = 1 - x_new[pos_y, pos_x]\n",
    "        if x_new.tostring() not in xs_strings:\n",
    "            return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_strings = {x.tostring() for x in xs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "ds = tf.data.Dataset.zip((\n",
    "    tf.data.Dataset.from_tensor_slices(xs),\n",
    "    tf.data.Dataset.from_tensor_slices(ys)\n",
    ")).shuffle(buffer_size=len(ys)).repeat()\n",
    "\n",
    "def augment(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flip up to 3 bits randomly\"\"\"\n",
    "    if np.random.uniform() > 0.5:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.85:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.95:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def map_fn(x: tf.Tensor, y: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = tf.numpy_function(func=augment , inp=[x], Tout=tf.float64)\n",
    "    x.set_shape([HEIGHT, WIDTH, 1])\n",
    "    return x, y\n",
    "\n",
    "ds = ds.map(map_fn, num_parallel_calls=8)\n",
    "ds = ds.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(4, 2, activation=\"relu\", padding=\"valid\", input_shape=(WIDTH, HEIGHT, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 2,  activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(16, 2,  activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025), metrics=[\"accuracy\"], loss=tf.keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training is fast, so let's just go crazy with the number of epochs\n",
    "for i in range(50):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=5e-05>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 712ms/step - loss: 0.3415 - accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3414769768714905, 0.89453125]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds, steps=len(ys) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06978682071417013, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kling\\cv_homework\\cv_venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 5x5_4-8-16_filters.savedmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"5x5_4-8-16_filters.savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"5x5_4-8-16_filters.savedmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 4)           20        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 8)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 16)          528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 854\n",
      "Trainable params: 854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    base_name = f\"weights/conv{i}_{{}}.npy\"\n",
    "    kernel, bias = model.layers[i].weights\n",
    "    np.save(base_name.format(\"kernel\"), kernel.numpy())\n",
    "    np.save(base_name.format(\"bias\"), bias.numpy())\n",
    "    \n",
    "kernel, bias = model.layers[4].weights\n",
    "np.save(\"weights/dense_kernel.npy\", kernel.numpy())\n",
    "np.save(\"weights/dense_bias.npy\", bias.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
