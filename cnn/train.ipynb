{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create shifted versions.  \n",
    "This is not redundant, even though we are using convolutional layers, as there are boundary effects (especially with the very small size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 5\n",
    "HEIGHT = 5\n",
    "\n",
    "with open(\"data.txt\") as f:\n",
    "    t = f.read()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for ex in t.split(\"\\n\\n\"):\n",
    "    lines = ex.split(\"\\n\")\n",
    "    y  = int(lines[0])\n",
    "    x = np.array([[0 if x == \".\" else 1 for x in line] for line in lines[1:]])\n",
    "    \n",
    "    ex_width = np.max(np.arange(1, WIDTH + 1) * x)\n",
    "    ex_height = np.max((np.arange(1, HEIGHT + 1) * x.T).T)\n",
    "    print(y, ex_width, ex_height, end=\"\")\n",
    "    for offset_x, offset_y in itertools.product(range(WIDTH - ex_width + 1),\n",
    "                                                range(HEIGHT - ex_height + 1)):\n",
    "        xs.append(np.roll(x, (offset_y, offset_x), axis=(0, 1)))\n",
    "        ys.append(y)\n",
    "        print(\".\", end=\"\")\n",
    "    print()\n",
    "\n",
    "xs = np.array(xs).astype(float)[..., np.newaxis]\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# of (shifted) examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    78\n",
       "9    74\n",
       "6    74\n",
       "5    73\n",
       "1    68\n",
       "4    61\n",
       "0    56\n",
       "8    44\n",
       "2    43\n",
       "7    31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[0 1 1 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(ys))\n",
    "print(ys[i])\n",
    "print(xs[i,:,:,0].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add augmentation & create tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(x: np.ndarray, xs_strings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Randomly flips a bit in x, ensuring that the resulting pattern\n",
    "       does not occurr in xs_strings\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        x_new = x.copy()\n",
    "        pos_y = np.random.randint(0, HEIGHT)\n",
    "        pos_x = np.random.randint(0, WIDTH)\n",
    "        x_new[pos_y, pos_x] = 1 - x_new[pos_y, pos_x]\n",
    "        if x_new.tostring() not in xs_strings:\n",
    "            return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_strings = {x.tostring() for x in xs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "ds = tf.data.Dataset.zip((\n",
    "    tf.data.Dataset.from_tensor_slices(xs),\n",
    "    tf.data.Dataset.from_tensor_slices(ys)\n",
    ")).shuffle(buffer_size=len(ys)).repeat()\n",
    "\n",
    "def augment(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flip up to 3 bits randomly\"\"\"\n",
    "    if np.random.uniform() > 0.6:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.85:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    if np.random.uniform() > 0.95:\n",
    "        x = random_flip(x, xs_strings)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def map_fn(x: tf.Tensor, y: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = tf.numpy_function(func=augment , inp=[x], Tout=tf.float64)\n",
    "    x.set_shape([HEIGHT, WIDTH, 1])\n",
    "    return x, y\n",
    "\n",
    "ds = ds.map(map_fn, num_parallel_calls=8)\n",
    "ds = ds.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "regularization actually improves training accuracy (?) and makes led activation patterns nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 2,\n",
    "        activation=\"relu\", padding=\"valid\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=0.001),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=0.001),\n",
    "        input_shape=(WIDTH, HEIGHT, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 2, activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=0.001),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=0.001),),\n",
    "    tf.keras.layers.Conv2D(16, 2, activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l2=0.001),\n",
    "        bias_regularizer=tf.keras.regularizers.L1L2(l2=0.001),),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025), metrics=[\"accuracy\"], loss=tf.keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training is fast, so let's just go crazy with the number of epochs\n",
    "for i in range(100):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0005>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "for i in range(20):\n",
    "    model.fit(ds, epochs=100, verbose=0, steps_per_epoch=len(ys) // BATCH_SIZE)\n",
    "    print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4517 - accuracy: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4516589343547821, 0.890625]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds, steps=len(ys) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14010281479635903, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(xs, ys, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 5, 5), dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[model.predict_classes(xs) != ys][...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kling\\cv_homework\\cv_venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 5x5_4-8-16_filters.savedmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"5x5_4-8-16_filters.savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"5x5_4-8-16_filters.savedmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 4)           20        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 8)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 16)          528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 854\n",
      "Trainable params: 854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [0,1,1,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,1,1,1,0],\n",
    "    [0,0,0,0,0]\n",
    "    ])[np.newaxis,..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104350, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.0185980e-04, 9.9014634e-01, 1.9110986e-03, 6.5210951e-03,\n",
       "        1.5079939e-06, 5.9689349e-04, 6.7623019e-05, 2.2448589e-04,\n",
       "        1.5240769e-04, 2.7672789e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    base_name = f\"weights/conv{i}_{{}}.npy\"\n",
    "    kernel, bias = model.layers[i].weights\n",
    "    np.save(base_name.format(\"kernel\"), kernel.numpy())\n",
    "    np.save(base_name.format(\"bias\"), bias.numpy())\n",
    "    \n",
    "kernel, bias = model.layers[4].weights\n",
    "np.save(\"weights/dense_kernel.npy\", kernel.numpy())\n",
    "np.save(\"weights/dense_bias.npy\", bias.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output model for inclusion in C code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 99th percentile activation strengths for led brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xs\n",
    "for i in range(3):\n",
    "    x = model.layers[i](x)\n",
    "    perc_99 = np.percentile(x, 99)\n",
    "    print(f\"const float conv{i}_activation_99per = {np.format_float_positional(perc_99)};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_float_array(name: str, x: np.ndarray) -> None:\n",
    "    assert(len(x.shape) == 1)\n",
    "    print(f\"const float {name}[] = {{\")\n",
    "    for i in range(int(np.ceil(len(x) / 5))):\n",
    "        print(\"    \" + \", \".join(np.format_float_scientific(f) for f in x[i*5: i*5 + 5]) + \",\")\n",
    "    print(\"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print_float_array(\n",
    "        f\"conv{i}_kernel_data\",\n",
    "        model.layers[i].weights[0].numpy().flatten()\n",
    "    )\n",
    "    print()\n",
    "    print_float_array(\n",
    "        f\"conv{i}_bias_data\",\n",
    "        model.layers[i].weights[1].numpy().flatten()\n",
    "    )\n",
    "    print()\n",
    "    \n",
    "print_float_array(\n",
    "    \"dense_kernel_data\",\n",
    "    model.layers[4].weights[0].numpy().T.flatten()\n",
    ")\n",
    "print()\n",
    "print_float_array(\n",
    "    \"dense_bias_data\",\n",
    "    model.layers[4].weights[1].numpy().flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
